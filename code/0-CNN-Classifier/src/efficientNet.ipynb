{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HApzzkH9nXv8"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LERN_bZnm6eY"
   },
   "source": [
    "# Basic Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nnFSdyr2pRGQ"
   },
   "outputs": [],
   "source": [
    "class ConvBnAct(nn.Module):\n",
    "  \"\"\"Layer grouping a convolution, batchnorm, and activation function\"\"\"\n",
    "  def __init__(self, n_in, n_out, kernel_size=3, \n",
    "               stride=1, padding=0, groups=1, bias=False,\n",
    "               bn=True, act=True):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.conv = nn.Conv2d(n_in, n_out, kernel_size=kernel_size,\n",
    "                          stride=stride, padding=padding,\n",
    "                          groups=groups, bias=bias)\n",
    "    self.bn = nn.BatchNorm2d(n_out) if bn else nn.Identity()\n",
    "    self.act = nn.SiLU() if act else nn.Identity()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.conv(x)\n",
    "    x = self.bn(x)\n",
    "    x = self.act(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mzajA0I_pSLn"
   },
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "  \"\"\"Squeeze-and-excitation block\"\"\"\n",
    "  def __init__(self, n_in, r=24):\n",
    "    super().__init__()\n",
    "\n",
    "    self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "    self.excitation = nn.Sequential(nn.Conv2d(n_in, n_in//r, kernel_size=1),\n",
    "                                    nn.SiLU(),\n",
    "                                    nn.Conv2d(n_in//r, n_in, kernel_size=1),\n",
    "                                    nn.Sigmoid())\n",
    "  \n",
    "  def forward(self, x):\n",
    "    y = self.squeeze(x)\n",
    "    y = self.excitation(y)\n",
    "    return x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nyLMmP0opTB-"
   },
   "outputs": [],
   "source": [
    "class DropSample(nn.Module):\n",
    "  \"\"\"Drops each sample in x with probability p during training\"\"\"\n",
    "  def __init__(self, p=0):\n",
    "    super().__init__()\n",
    "\n",
    "    self.p = p\n",
    "  \n",
    "  def forward(self, x):\n",
    "    if (not self.p) or (not self.training):\n",
    "      return x\n",
    "    \n",
    "    batch_size = len(x)\n",
    "    random_tensor = torch.cuda.FloatTensor(batch_size, 1, 1, 1).uniform_()\n",
    "    bit_mask = self.p<random_tensor\n",
    "\n",
    "    x = x.div(1-self.p)\n",
    "    x = x * bit_mask\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DxFlLaR-pUVe"
   },
   "outputs": [],
   "source": [
    "class MBConvN(nn.Module):\n",
    "  \"\"\"MBConv with an expansion factor of N, plus squeeze-and-excitation\"\"\"\n",
    "  def __init__(self, n_in, n_out, expansion_factor,\n",
    "               kernel_size=3, stride=1, r=24, p=0):\n",
    "    super().__init__()\n",
    "\n",
    "    padding = (kernel_size-1)//2\n",
    "    expanded = expansion_factor*n_in\n",
    "    self.skip_connection = (n_in == n_out) and (stride == 1)\n",
    "\n",
    "    self.expand_pw = nn.Identity() if (expansion_factor == 1) else ConvBnAct(n_in, expanded, kernel_size=1)\n",
    "    self.depthwise = ConvBnAct(expanded, expanded, kernel_size=kernel_size, \n",
    "                               stride=stride, padding=padding, groups=expanded)\n",
    "    self.se = SEBlock(expanded, r=r)\n",
    "    self.reduce_pw = ConvBnAct(expanded, n_out, kernel_size=1,\n",
    "                               act=False)\n",
    "    self.dropsample = DropSample(p)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    residual = x\n",
    "\n",
    "    x = self.expand_pw(x)\n",
    "    x = self.depthwise(x)\n",
    "    x = self.se(x)\n",
    "    x = self.reduce_pw(x)\n",
    "\n",
    "    if self.skip_connection:\n",
    "      x = self.dropsample(x)\n",
    "      x = x + residual\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AVcEwdHhpVb1"
   },
   "outputs": [],
   "source": [
    "class MBConv1(MBConvN):\n",
    "  def __init__(self, n_in, n_out, kernel_size=3,\n",
    "               stride=1, r=24, p=0):\n",
    "    super().__init__(n_in, n_out, expansion_factor=1,\n",
    "                     kernel_size=kernel_size, stride=stride,\n",
    "                     r=r, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Jcy8HrinpWwM"
   },
   "outputs": [],
   "source": [
    "class MBConv6(MBConvN):\n",
    "  def __init__(self, n_in, n_out, kernel_size=3,\n",
    "               stride=1, r=24, p=0):\n",
    "    super().__init__(n_in, n_out, expansion_factor=6,\n",
    "                     kernel_size=kernel_size, stride=stride,\n",
    "                     r=r, p=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlyzgJaUnDOb"
   },
   "source": [
    "# Scaling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kpSJO3bez_IH"
   },
   "outputs": [],
   "source": [
    "def create_stage(n_in, n_out, num_layers, layer_type=MBConv6, \n",
    "                 kernel_size=3, stride=1, r=24, p=0):\n",
    "  \"\"\"Creates a Sequential consisting of [num_layers] layer_type\"\"\"\n",
    "  layers = [layer_type(n_in, n_out, kernel_size=kernel_size,\n",
    "                       stride=stride, r=r, p=p)]\n",
    "  layers += [layer_type(n_out, n_out, kernel_size=kernel_size,\n",
    "                        r=r, p=p) for _ in range(num_layers-1)]\n",
    "  layers = nn.Sequential(*layers)\n",
    "  return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ekRQVrM9rW_D"
   },
   "outputs": [],
   "source": [
    "def scale_width(w, w_factor):\n",
    "  \"\"\"Scales width given a scale factor\"\"\"\n",
    "  w *= w_factor\n",
    "  new_w = (int(w+4) // 8) * 8\n",
    "  new_w = max(8, new_w)\n",
    "  if new_w < 0.9*w:\n",
    "     new_w += 8\n",
    "  return int(new_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMPHLA04nG_B"
   },
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JsFzF7SSP9QE"
   },
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "  \"\"\"Generic EfficientNet that takes in the width and depth scale factors and scales accordingly\"\"\"\n",
    "  def __init__(self, w_factor=1, d_factor=1,\n",
    "               out_sz=1000):\n",
    "    super().__init__()\n",
    "\n",
    "    base_widths = [(32, 16), (16, 24), (24, 40),\n",
    "                   (40, 80), (80, 112), (112, 192),\n",
    "                   (192, 320), (320, 1280)]\n",
    "    base_depths = [1, 2, 2, 3, 3, 4, 1]\n",
    "\n",
    "    scaled_widths = [(scale_width(w[0], w_factor), scale_width(w[1], w_factor)) \n",
    "                     for w in base_widths]\n",
    "    scaled_depths = [math.ceil(d_factor*d) for d in base_depths]\n",
    "    \n",
    "    kernel_sizes = [3, 3, 5, 3, 5, 5, 3]\n",
    "    strides = [1, 2, 2, 2, 1, 2, 1]\n",
    "    ps = [0, 0.029, 0.057, 0.086, 0.114, 0.143, 0.171]\n",
    "\n",
    "    self.stem = ConvBnAct(3, scaled_widths[0][0], stride=2, padding=1)\n",
    "    \n",
    "    stages = []\n",
    "    for i in range(7):\n",
    "      layer_type = MBConv1 if (i == 0) else MBConv6\n",
    "      r = 4 if (i == 0) else 24\n",
    "      stage = create_stage(*scaled_widths[i], scaled_depths[i],\n",
    "                           layer_type, kernel_size=kernel_sizes[i], \n",
    "                           stride=strides[i], r=r, p=ps[i])\n",
    "      stages.append(stage)\n",
    "    self.stages = nn.Sequential(*stages)\n",
    "\n",
    "    self.pre_head = ConvBnAct(*scaled_widths[-1], kernel_size=1)\n",
    "\n",
    "    self.head = nn.Sequential(nn.AdaptiveAvgPool2d(1),\n",
    "                              nn.Flatten(),\n",
    "                              nn.Linear(scaled_widths[-1][1], out_sz))\n",
    "\n",
    "  def feature_extractor(self, x):\n",
    "    x = self.stem(x)\n",
    "    x = self.stages(x)\n",
    "    x = self.pre_head(x)\n",
    "    return x\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.feature_extractor(x)\n",
    "    x = self.head(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wPmtAwwftE_t"
   },
   "outputs": [],
   "source": [
    "class EfficientNetB0(EfficientNet):\n",
    "  def __init__(self, out_sz=1000):\n",
    "    w_factor = 1\n",
    "    d_factor = 1\n",
    "    super().__init__(w_factor, d_factor, out_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4NGMQZlPXer_"
   },
   "outputs": [],
   "source": [
    "class EfficientNetB1(EfficientNet):\n",
    "  def __init__(self, out_sz=1000):\n",
    "    w_factor = 1\n",
    "    d_factor = 1.1\n",
    "    super().__init__(w_factor, d_factor, out_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7UT9TiXfYII3"
   },
   "outputs": [],
   "source": [
    "class EfficientNetB2(EfficientNet):\n",
    "  def __init__(self, out_sz=1000):\n",
    "    w_factor = 1.1\n",
    "    d_factor = 1.2\n",
    "    super().__init__(w_factor, d_factor, out_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lBXKxCnzYO1p"
   },
   "outputs": [],
   "source": [
    "class EfficientNetB3(EfficientNet):\n",
    "  def __init__(self, out_sz=1000):\n",
    "    w_factor = 1.2\n",
    "    d_factor = 1.4\n",
    "    super().__init__(w_factor, d_factor, out_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Y4QFCHapYQv0"
   },
   "outputs": [],
   "source": [
    "class EfficientNetB4(EfficientNet):\n",
    "  def __init__(self, out_sz=1000):\n",
    "    w_factor = 1.4\n",
    "    d_factor = 1.8\n",
    "    super().__init__(w_factor, d_factor, out_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8kcOAyBEYSrk"
   },
   "outputs": [],
   "source": [
    "class EfficientNetB5(EfficientNet):\n",
    "  def __init__(self, out_sz=1000):\n",
    "    w_factor = 1.6\n",
    "    d_factor = 2.2\n",
    "    super().__init__(w_factor, d_factor, out_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "A_-4TCR3YUyL"
   },
   "outputs": [],
   "source": [
    "class EfficientNetB6(EfficientNet):\n",
    "  def __init__(self, out_sz=1000):\n",
    "    w_factor = 1.8\n",
    "    d_factor = 2.6\n",
    "    super().__init__(w_factor, d_factor, out_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HAWkZo9KYYVg"
   },
   "outputs": [],
   "source": [
    "class EfficientNetB7(EfficientNet):\n",
    "  def __init__(self, out_sz=1000):\n",
    "    w_factor = 2\n",
    "    d_factor = 3.1\n",
    "    super().__init__(w_factor, d_factor, out_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Thread count, will use half of it to load the data\n",
    "THREADS = 4\n",
    "ROOT = '../data/imagenette2'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 4\n",
    "classes = [_ for _ in os.listdir(ROOT + '/train')]\n",
    "net = EfficientNetB7(out_sz=len(classes))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train(trainloader, testloader, epochs=2):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    # optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    print('Training start:', time.asctime(time.localtime()))\n",
    "    for epoch in range(epochs):\n",
    "        torch.cuda.empty_cache()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Epoch:', epoch)\n",
    "        torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    print('Finished Training:', time.asctime(time.localtime()))\n",
    "    end_time = time.perf_counter()\n",
    "    print('Training time:', end_time - start_time)\n",
    "\n",
    "\n",
    "def test(testloader):\n",
    "    correct_pred = {classname: 0 for classname in classes}\n",
    "    total_pred = {classname: 0 for classname in classes}\n",
    "    all_correct = 0\n",
    "    all_preds = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predictions = torch.max(outputs.data, 1)\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred[classes[label]] += 1\n",
    "                    all_correct += 1\n",
    "                total_pred[classes[label]] += 1\n",
    "                all_preds += 1\n",
    "\n",
    "    print(f\"General accuracy for this classifier: {(100 * float(all_correct) / float(all_preds)):.1f}%\")\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(f\"Accuracy for class: {classname} is {accuracy:.1f}%\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(128),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.ImageFolder(root=ROOT + '/train', transform=transform)\n",
    "    _trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=THREADS//2)\n",
    "\n",
    "    testset = torchvision.datasets.ImageFolder(root=ROOT + '/test', transform=transform)\n",
    "    _testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=THREADS//2)\n",
    "\n",
    "    return _trainloader, _testloader\n",
    "\n",
    "\n",
    "def train_and_save(trainloader, testloader, PATH, epochs=2):\n",
    "    # Training\n",
    "    train(trainloader, testloader, epochs)\n",
    "    # Saving the model\n",
    "    torch.save(net.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program starting: Mon Apr 11 02:59:35 2022\n",
      "Training start: Mon Apr 11 02:59:35 2022\n",
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Finished Training: Mon Apr 11 03:35:30 2022\n",
      "Training time: 2155.0323498\n",
      "General accuracy for this classifier: 17.3%\n",
      "Accuracy for class: n01440764 is 9.8%\n",
      "Accuracy for class: n02102040 is 5.3%\n",
      "Accuracy for class: n02979186 is 22.1%\n",
      "Accuracy for class: n03000684 is 3.4%\n",
      "Accuracy for class: n03028079 is 25.2%\n",
      "Accuracy for class: n03394916 is 19.8%\n",
      "Accuracy for class: n03417042 is 26.2%\n",
      "Accuracy for class: n03425413 is 12.4%\n",
      "Accuracy for class: n03445777 is 15.0%\n",
      "Accuracy for class: n03888257 is 34.1%\n"
     ]
    }
   ],
   "source": [
    "print('Program starting:', time.asctime(time.localtime()))\n",
    "net.to(device)\n",
    "trainloader, testloader = main()\n",
    "\n",
    "# Saving the model\n",
    "PATH = '../models/efficient_net_tut.pth'\n",
    "\n",
    "train_and_save(trainloader, testloader, PATH, epochs=5)\n",
    "\n",
    "# Loading the model\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# Test over 10000 images\n",
    "test(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "LERN_bZnm6eY",
    "GlyzgJaUnDOb",
    "cMPHLA04nG_B"
   ],
   "name": "efficientNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
